{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR12uvMqlYHbppRl2wGHun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bejaeger/ProScanNet/blob/main/ProScanNet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DITYGZtzSSU",
        "outputId": "a7573762-60ab-4896-e3d9-48f50efd9a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'ProScanNet'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 86 (delta 48), reused 57 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (86/86), 25.64 KiB | 2.85 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/ProScanNet\n",
            "Already up to date.\n",
            "Already up to date.\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/bejaeger/ProScanNet\n",
        "\n",
        "%cd ProScanNet\n",
        "!git pull\n",
        "!git config pull.rebase false\n",
        "!git pull\n",
        "\n",
        "!pip install -r requirements.txt  # Assuming you have a requirements.txt file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss,  Module\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from dataset import CustomDataset\n",
        "from data_utils import TorchDataset, preprocess\n",
        "from model import *"
      ],
      "metadata": {
        "id": "MzTRvF5WJtxW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import CustomDataset\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/MLProjects/chaimeleon/data/train\"\n",
        "dataset = CustomDataset(dataset_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hryzYYb52e0N",
        "outputId": "73c1a18a-92ef-4be3-e208-b6afb8fc46f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 295/295 [00:32<00:00,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded Dataset with 295 images, 85 of which are high grade. Average age: 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "train_portion = 0.8"
      ],
      "metadata": {
        "id": "KTNdjsrA7k5s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = preprocess(images=dataset.image_data)  # pad images to have depth 40 (found to be max depth)\n",
        "labels = dataset.labels\n",
        "\n",
        "# TODO: Improve split to enusre equal amounts of positive labels in train and val\n",
        "train_images = images[:int(len(images) * train_portion)]\n",
        "train_labels = labels[:int(len(labels) * train_portion)]\n",
        "val_images = images[int(len(images) * train_portion):]\n",
        "val_labels = labels[int(len(labels) * train_portion):]\n",
        "\n",
        "print(f\"[train set] num positive/negative labels: {sum(train_labels)} / {len(train_labels) - sum(train_labels)}\")\n",
        "print(f\"[val set] num positive/negative labels: {sum(val_labels)} / {len(val_labels) - sum(val_labels)}\")\n",
        "\n",
        "train_dataset = TorchDataset(images=train_images, labels=train_labels)\n",
        "val_dataset = TorchDataset(images=val_images, labels=val_labels)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WEYaOr77pBR",
        "outputId": "6053cbcf-fbb1-4493-b270-6c236409ede7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train set] num positive/negative labels: 63 / 173\n",
            "[val set] num positive/negative labels: 22 / 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet3D()\n",
        "loss_fn = CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "VD4pgKIs75ia"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MX_dhT3J9Ee",
        "outputId": "1782cc4a-177e-4428-bc2e-17bd08565f08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet3D(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv3d(1, 8, kernel_size=(11, 11, 11), stride=(4, 4, 4))\n",
            "    (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv3d(8, 12, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
            "    (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv3d(12, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.7, inplace=False)\n",
            "    (1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.7, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "  )\n",
            "  (dropout_conv): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: Module, loader: DataLoader, loss_fn: Callable) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loss = 0\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss += loss_fn(outputs, labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    loss = loss / len(loader)\n",
        "    model.train()\n",
        "    return accuracy, loss\n",
        "\n",
        "print(\"Begin training with model\")\n",
        "print(model)\n",
        "\n",
        "model.train()\n",
        "iteration_index = 0\n",
        "for epoch in range(num_epochs):\n",
        "    train_losses = []\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        iteration_index += 1\n",
        "\n",
        "    train_accuracy, _ = evaluate(model=model, loader=train_loader, loss_fn=loss_fn)\n",
        "    val_accuracy, val_loss = evaluate(model=model, loader=val_loader, loss_fn=loss_fn)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
        "        f\"Train loss: {torch.mean(torch.tensor(train_losses)):.3f}, Val loss: {val_loss:.3f}, \"\n",
        "        f\"Train accuracy: {train_accuracy:.3f}, \"\n",
        "        f\"Val accuracy: {val_accuracy:.3f}\")\n",
        "\n",
        "output_path = \"checkpoints/model.pth\"\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "print(f\"Saving model to `{output_path}`...\")\n",
        "torch.save(model.state_dict(), \"checkpoints/model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiK8ADgt8d40",
        "outputId": "6b42100d-59f3-4dde-df06-2e9088362e88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training with model\n",
            "AlexNet3D(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv3d(1, 8, kernel_size=(11, 11, 11), stride=(4, 4, 4))\n",
            "    (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv3d(8, 12, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
            "    (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv3d(12, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.7, inplace=False)\n",
            "    (1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.7, inplace=False)\n",
            "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "  )\n",
            "  (dropout_conv): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "[Epoch 1/50] Train loss: 0.368, Val loss: 0.743, Train accuracy: 90.254, Val accuracy: 61.017\n",
            "[Epoch 2/50] Train loss: 0.335, Val loss: 0.794, Train accuracy: 87.288, Val accuracy: 45.763\n",
            "[Epoch 3/50] Train loss: 0.296, Val loss: 1.112, Train accuracy: 80.085, Val accuracy: 54.237\n",
            "[Epoch 4/50] Train loss: 0.249, Val loss: 2.197, Train accuracy: 73.305, Val accuracy: 62.712\n",
            "[Epoch 5/50] Train loss: 0.344, Val loss: 0.943, Train accuracy: 95.763, Val accuracy: 71.186\n",
            "[Epoch 6/50] Train loss: 0.350, Val loss: 1.368, Train accuracy: 95.763, Val accuracy: 61.017\n",
            "[Epoch 7/50] Train loss: 0.298, Val loss: 1.080, Train accuracy: 96.186, Val accuracy: 57.627\n",
            "[Epoch 8/50] Train loss: 0.276, Val loss: 1.148, Train accuracy: 86.864, Val accuracy: 67.797\n",
            "[Epoch 9/50] Train loss: 0.327, Val loss: 0.932, Train accuracy: 95.763, Val accuracy: 59.322\n",
            "[Epoch 10/50] Train loss: 0.225, Val loss: 1.530, Train accuracy: 52.966, Val accuracy: 35.593\n",
            "[Epoch 11/50] Train loss: 0.276, Val loss: 0.968, Train accuracy: 93.220, Val accuracy: 47.458\n",
            "[Epoch 12/50] Train loss: 0.230, Val loss: 1.477, Train accuracy: 93.220, Val accuracy: 66.102\n",
            "[Epoch 13/50] Train loss: 0.149, Val loss: 1.794, Train accuracy: 61.017, Val accuracy: 37.288\n",
            "[Epoch 14/50] Train loss: 0.192, Val loss: 1.513, Train accuracy: 95.339, Val accuracy: 71.186\n",
            "[Epoch 15/50] Train loss: 0.121, Val loss: 1.857, Train accuracy: 84.322, Val accuracy: 66.102\n",
            "[Epoch 16/50] Train loss: 0.117, Val loss: 1.483, Train accuracy: 84.322, Val accuracy: 49.153\n",
            "[Epoch 17/50] Train loss: 0.186, Val loss: 1.425, Train accuracy: 99.153, Val accuracy: 64.407\n",
            "[Epoch 18/50] Train loss: 0.229, Val loss: 6.925, Train accuracy: 73.305, Val accuracy: 62.712\n",
            "[Epoch 19/50] Train loss: 0.327, Val loss: 1.899, Train accuracy: 75.000, Val accuracy: 66.102\n",
            "[Epoch 20/50] Train loss: 0.203, Val loss: 1.880, Train accuracy: 67.373, Val accuracy: 38.983\n",
            "[Epoch 21/50] Train loss: 0.167, Val loss: 2.403, Train accuracy: 86.441, Val accuracy: 67.797\n",
            "[Epoch 22/50] Train loss: 0.169, Val loss: 2.797, Train accuracy: 79.661, Val accuracy: 67.797\n",
            "[Epoch 23/50] Train loss: 0.129, Val loss: 1.248, Train accuracy: 98.729, Val accuracy: 61.017\n",
            "[Epoch 24/50] Train loss: 0.156, Val loss: 1.468, Train accuracy: 100.000, Val accuracy: 61.017\n",
            "[Epoch 25/50] Train loss: 0.108, Val loss: 2.009, Train accuracy: 89.407, Val accuracy: 64.407\n",
            "[Epoch 26/50] Train loss: 0.184, Val loss: 1.423, Train accuracy: 99.153, Val accuracy: 67.797\n",
            "[Epoch 27/50] Train loss: 0.160, Val loss: 2.538, Train accuracy: 75.000, Val accuracy: 64.407\n",
            "[Epoch 28/50] Train loss: 0.077, Val loss: 1.532, Train accuracy: 87.288, Val accuracy: 44.068\n",
            "[Epoch 29/50] Train loss: 0.098, Val loss: 3.041, Train accuracy: 91.949, Val accuracy: 64.407\n",
            "[Epoch 30/50] Train loss: 0.119, Val loss: 1.511, Train accuracy: 92.797, Val accuracy: 52.542\n",
            "[Epoch 31/50] Train loss: 0.112, Val loss: 0.842, Train accuracy: 90.254, Val accuracy: 66.102\n",
            "[Epoch 32/50] Train loss: 0.141, Val loss: 3.022, Train accuracy: 80.508, Val accuracy: 66.102\n",
            "[Epoch 33/50] Train loss: 0.171, Val loss: 1.947, Train accuracy: 92.797, Val accuracy: 55.932\n",
            "[Epoch 34/50] Train loss: 0.137, Val loss: 2.046, Train accuracy: 91.949, Val accuracy: 47.458\n",
            "[Epoch 35/50] Train loss: 0.132, Val loss: 4.863, Train accuracy: 76.271, Val accuracy: 67.797\n",
            "[Epoch 36/50] Train loss: 0.084, Val loss: 2.899, Train accuracy: 93.644, Val accuracy: 69.492\n",
            "[Epoch 37/50] Train loss: 0.104, Val loss: 3.136, Train accuracy: 78.390, Val accuracy: 66.102\n",
            "[Epoch 38/50] Train loss: 0.180, Val loss: 3.012, Train accuracy: 82.203, Val accuracy: 67.797\n",
            "[Epoch 39/50] Train loss: 0.130, Val loss: 3.904, Train accuracy: 81.356, Val accuracy: 64.407\n",
            "[Epoch 40/50] Train loss: 0.189, Val loss: 2.139, Train accuracy: 58.051, Val accuracy: 37.288\n",
            "[Epoch 41/50] Train loss: 0.118, Val loss: 1.174, Train accuracy: 100.000, Val accuracy: 64.407\n",
            "[Epoch 42/50] Train loss: 0.106, Val loss: 7.017, Train accuracy: 73.305, Val accuracy: 62.712\n",
            "[Epoch 43/50] Train loss: 0.142, Val loss: 1.414, Train accuracy: 98.729, Val accuracy: 54.237\n",
            "[Epoch 44/50] Train loss: 0.141, Val loss: 1.964, Train accuracy: 90.678, Val accuracy: 42.373\n",
            "[Epoch 45/50] Train loss: 0.130, Val loss: 2.569, Train accuracy: 88.983, Val accuracy: 62.712\n",
            "[Epoch 46/50] Train loss: 0.090, Val loss: 1.877, Train accuracy: 96.186, Val accuracy: 66.102\n",
            "[Epoch 47/50] Train loss: 0.065, Val loss: 2.318, Train accuracy: 98.305, Val accuracy: 66.102\n",
            "[Epoch 48/50] Train loss: 0.053, Val loss: 3.509, Train accuracy: 90.254, Val accuracy: 66.102\n",
            "[Epoch 49/50] Train loss: 0.061, Val loss: 1.504, Train accuracy: 100.000, Val accuracy: 57.627\n",
            "[Epoch 50/50] Train loss: 0.065, Val loss: 1.880, Train accuracy: 100.000, Val accuracy: 67.797\n",
            "Saving model to `checkpoints/model.pth`...\n"
          ]
        }
      ]
    }
  ]
}